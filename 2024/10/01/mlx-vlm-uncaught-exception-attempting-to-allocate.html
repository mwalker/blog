<!doctype html>
<html lang="en-AU">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Further Notes… on mlx-vlm uncaught exception attempting to allocate</title>
<meta name="description" content="" />
<!-- link rel="stylesheet" href="https://cdn.simplecss.org/simple.css" -->
<link rel="stylesheet" href="/assets/css/style.css">

<link rel="icon" href="/assets/images/favicon.svg" />
<link rel="apple-touch-icon" href="/assets/images/favicon.png">

<link rel="canonical" href="/2024/10/01/mlx-vlm-uncaught-exception-attempting-to-allocate.html">
<link rel="alternate" type="application/rss+xml" title="Further Notes…" href="/feed.xml">
  </head>
  <body>

    <header>
      <nav>
  <a href="/">Further Notes…</a>
  
  <a href="/tags" >tags</a>
  
  <a href="https://raindrop.io/gunzel/public-48037709/sort=-created&perpage=30&page=0" >links</a>
  
  <a href="https://www.librarything.com/profile/gunzel" >library</a>
  
  <a href="https://github.com/mwalker" >code</a>
  
  <a href="/feed.xml" >rss</a>
  
</nav>

      <h1>mlx-vlm uncaught exception attempting to allocate</h1>
    </header>

    <main>

      <p class="meta">Posted on 01 Oct 2024</p>

<p>A <a href="https://simonwillison.net/2024/Sep/29/mlx-vlm/">followup post from Simon Willison on Qwen2VL</a> and using it with <a href="https://github.com/Blaizzy/mlx-vlm">mlx-vlm</a> to run locally on Apple Silicon got me intrigued, as though I’ve been experimenting fairly successfully on Hugging Face I always seem to run out of quota at an inopportune time.</p>

<p>Using uv as described got it running fairly easily, just a bit of a wait for the weights to download. But every time I ran it I would get an error like:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>libc++abi: terminating due to uncaught exception of type std::runtime_error: Attempting to allocate 96905199616 bytes which is greater than the maximum allowed buffer size of 17179869184 bytes.
</code></pre></div></div>

<p>After a fruitless process of quitting all other apps, disconnecting the external monitor, upgrading macOS, homebrew, and replacing homebrew python with uv python I eventually twigged with the help of <a href="https://github.com/ml-explore/mlx-swift-examples/issues/106">this thread</a> that the problem might be with the size of the image I was using for testing, this is probably obvious, and should be obvious to me in light of my previous experiments in generating images. The cutoff for me on a 32GB M1 Max MacBook Pro is somewhere a little north of 2000 pixels on the long side of the image.</p>

<p>Now I’m waiting for the weights of Qwen2-VL-7B-Instruct to download to see if that will run, and if so what the limits on image size are, and what the speed is like. Hopefully I will then have something I can run on demand.</p>

<p>Thinking about a dedicated machine to run this on I came across this <a href="https://llm-calc.rayfernando.ai">nifty calculator</a> and some <a href="https://github.com/XiongjieDai/GPU-Benchmarks-on-LLM-Inference">interesting benchmarks</a> that make me think Apple Silicon may be a viable option for me.</p>


<hr />

<p class="meta"><a href="/tag/ai/">#ai</a> <a href="/tag/llms/">#llms</a> <a href="/tag/vision-llms/">#vision&nbsp;llms</a> <a href="/tag/qwen/">#Qwen</a> <a href="/tag/handwritten-text-recognition/">#handwritten&nbsp;text&nbsp;recognition</a> <a href="/tag/digitisation/">#digitisation</a> <a href="/tag/mlx/">#mlx</a> <a href="/tag/mlx-vlm/">#mlx-vlm</a> </p>


    </main>

    <footer>
      <p>Copyright © 1990-2024 Matthew Walker.</p>
    </footer>

  </body>
</html>
